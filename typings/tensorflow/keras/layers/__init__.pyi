"""
This type stub file was generated by pyright.
"""

import tensorflow as tf
from _typeshed import Incomplete
from collections.abc import Callable, Iterable, Sequence
from typing import Any, Generic, Literal, TypeVar, overload, type_check_only
from typing_extensions import Self, TypeAlias
from tensorflow import Tensor, Variable
from tensorflow._aliases import AnyArray, DTypeLike, DataSequence, Float, TensorCompatible, TensorLike
from tensorflow.keras.activations import _Activation
from tensorflow.keras.constraints import Constraint
from tensorflow.keras.initializers import _Initializer
from tensorflow.keras.regularizers import Regularizer, _Regularizer



_InputT_contra = TypeVar("_InputT_contra", contravariant=True)
_OutputT_co = TypeVar("_OutputT_co", covariant=True)
class InputSpec:
    dtype: str | None
    shape: tuple[int | None, ...]
    ndim: int | None
    max_ndim: int | None
    min_ndim: int | None
    axes: dict[int, int | None] | None
    def __init__(self, dtype: DTypeLike | None = ..., shape: Iterable[int | None] | None = ..., ndim: int | None = ..., max_ndim: int | None = ..., min_ndim: int | None = ..., axes: dict[int, int | None] | None = ..., allow_last_axis_squeeze: bool = ..., name: str | None = ..., optional: bool = ...) -> None:
        ...

    def get_config(self) -> dict[str, Any]:
        ...

    @classmethod
    def from_config(cls, config: dict[str, Any]) -> type[Self]:
        ...



class Layer(tf.Module, Generic[_InputT_contra, _OutputT_co]):
    input_spec: InputSpec | Any
    @property
    def trainable(self) -> bool:
        ...

    @trainable.setter
    def trainable(self, value: bool) -> None:
        ...

    def __init__(self, *, activity_regularizer: _Regularizer = ..., trainable: bool = ..., dtype: DTypeLike | None = ..., autocast: bool = ..., name: str | None = ..., input_dim: int | None = ..., input_shape: Any = ...) -> None:
        ...

    def __call__(self, inputs: _InputT_contra, *, training: bool = ..., mask: TensorCompatible | None = ...) -> _OutputT_co:
        ...

    def call(self, inputs: _InputT_contra, /) -> _OutputT_co:
        ...

    def build(self, input_shape: Any, /) -> None:
        ...

    @overload
    def compute_output_shape(self: Layer[tf.Tensor, tf.Tensor], input_shape: tf.TensorShape, /) -> tf.TensorShape:
        ...

    @overload
    def compute_output_shape(self, input_shape: Any, /) -> Any:
        ...

    def add_weight(self, shape: Iterable[int | None] | None = ..., initializer: _Initializer | None = ..., dtype: DTypeLike | None = ..., trainable: bool = ..., autocast: bool = ..., regularizer: _Regularizer = ..., constraint: _Constraint = ..., aggregation: Literal["mean", "sum", "only_first_replica"] = ..., name: str | None = ...) -> tf.Variable:
        ...

    def add_loss(self, loss: tf.Tensor | Sequence[tf.Tensor] | Callable[[], tf.Tensor]) -> None:
        ...

    def count_params(self) -> int:
        ...

    @property
    def trainable_variables(self) -> list[Variable]:
        ...

    @property
    def non_trainable_variables(self) -> list[Variable]:
        ...

    @property
    def trainable_weights(self) -> list[Variable]:
        ...

    @property
    def non_trainable_weights(self) -> list[Variable]:
        ...

    @property
    def losses(self) -> list[Tensor]:
        ...

    def get_weights(self) -> list[AnyArray]:
        ...

    def set_weights(self, weights: Sequence[AnyArray]) -> None:
        ...

    def get_config(self) -> dict[str, Any]:
        ...

    @classmethod
    def from_config(cls, config: dict[str, Any]) -> Self:
        ...

    def __getattr__(self, name: str) -> Incomplete:
        ...



_LayerDtype: TypeAlias = DTypeLike | dict[str, Any] | Any
_Constraint: TypeAlias = str | dict[str, Any] | Constraint | None
@type_check_only
class _IndexLookup(Layer[tf.Tensor, tf.Tensor]):
    def __init__(self, max_tokens: int | None, num_oov_indices: int, mask_token: str | None, oov_token: str, vocabulary_dtype: Literal["int64", "string"], vocabulary: str | None | TensorCompatible = ..., idf_weights: TensorCompatible | None = ..., invert: bool = ..., output_mode: Literal["int", "count", "multi_hot", "one_hot", "tf_idf"] = ..., sparse: bool = ..., pad_to_max_tokens: bool = ..., name: str | None = ..., *, vocabulary_size: int | None = ..., has_input_vocabulary: bool = ..., trainable: bool | None = ..., dtype: _LayerDtype | None = ..., activity_regularizer: _Regularizer = ..., autocast: bool = ...) -> None:
        ...

    def compute_output_signature(self, input_spec) -> tf.TensorSpec:
        ...

    def get_vocabulary(self, include_special_tokens: bool = ...) -> list[Incomplete]:
        ...

    def vocabulary_size(self) -> int:
        ...



class StringLookup(_IndexLookup):
    def __init__(self, max_tokens: int | None = ..., num_oov_indices: int = ..., mask_token: str | None = ..., oov_token: str = ..., vocabulary: str | None | TensorCompatible = ..., idf_weights: TensorCompatible | None = ..., invert: bool = ..., output_mode: Literal["int", "count", "multi_hot", "one_hot", "tf_idf"] = ..., pad_to_max_tokens: bool = ..., sparse: bool = ..., encoding: str = ..., name: str | None = ..., *, vocabulary_size: int | None = ..., has_input_vocabulary: bool = ..., trainable: bool | None = ..., dtype: _LayerDtype | None = ..., activity_regularizer: _Regularizer = ..., autocast: bool = ...) -> None:
        ...

    def adapt(self, data: tf.data.Dataset[TensorLike] | AnyArray | DataSequence, steps: Float | None = ...) -> None:
        ...



class IntegerLookup(_IndexLookup):
    def __init__(self, max_tokens: int | None = ..., num_oov_indices: int = ..., mask_token: int | None = ..., oov_token: int = ..., vocabulary: str | None | TensorCompatible = ..., vocabulary_dtype: Literal["int64"] = ..., idf_weights: TensorCompatible | None = ..., invert: bool = ..., output_mode: Literal["int", "count", "multi_hot", "one_hot", "tf_idf"] = ..., sparse: bool = ..., pad_to_max_tokens: bool = ..., name: str | None = ..., *, vocabulary_size: int | None = ..., has_input_vocabulary: bool = ..., trainable: bool | None = ..., dtype: _LayerDtype | None = ..., activity_regularizer: _Regularizer = ..., autocast: bool = ...) -> None:
        ...

    def adapt(self, data: tf.data.Dataset[TensorLike] | AnyArray | DataSequence, steps: Float | None = ...) -> None:
        ...



class Dense(Layer[tf.Tensor, tf.Tensor]):
    def __init__(self, units: int, activation: _Activation = ..., use_bias: bool = ..., kernel_initializer: _Initializer = ..., bias_initializer: _Initializer = ..., kernel_regularizer: _Regularizer = ..., bias_regularizer: _Regularizer = ..., activity_regularizer: _Regularizer = ..., kernel_constraint: _Constraint = ..., bias_constraint: _Constraint = ..., lora_rank: int | None = ..., *, trainable: bool = ..., dtype: _LayerDtype | None = ..., autocast: bool = ..., name: str | None = ...) -> None:
        ...



class BatchNormalization(Layer[tf.Tensor, tf.Tensor]):
    def __init__(self, axis: int = ..., momentum: float = ..., epsilon: float = ..., center: bool = ..., scale: bool = ..., beta_initializer: _Initializer = ..., gamma_initializer: _Initializer = ..., moving_mean_initializer: _Initializer = ..., moving_variance_initializer: _Initializer = ..., beta_regularizer: _Regularizer = ..., gamma_regularizer: _Regularizer = ..., beta_constraint: _Constraint = ..., gamma_constraint: _Constraint = ..., synchronized: bool = ..., *, activity_regularizer: _Regularizer = ..., trainable: bool = ..., dtype: _LayerDtype | None = ..., autocast: bool = ..., name: str | None = ...) -> None:
        ...



class ReLU(Layer[tf.Tensor, tf.Tensor]):
    def __init__(self, max_value: float | None = ..., negative_slope: float | None = ..., threshold: float | None = ..., *, activity_regularizer: _Regularizer = ..., trainable: bool = ..., dtype: _LayerDtype | None = ..., autocast: bool = ..., name: str | None = ...) -> None:
        ...



class Dropout(Layer[tf.Tensor, tf.Tensor]):
    def __init__(self, rate: float, noise_shape: TensorCompatible | Sequence[int | None] | None = ..., seed: int | None = ..., *, activity_regularizer: _Regularizer = ..., trainable: bool = ..., dtype: _LayerDtype | None = ..., autocast: bool = ..., name: str | None = ...) -> None:
        ...



class Embedding(Layer[tf.Tensor, tf.Tensor]):
    def __init__(self, input_dim: int, output_dim: int, embeddings_initializer: _Initializer = ..., embeddings_regularizer: _Regularizer = ..., embeddings_constraint: _Constraint = ..., mask_zero: bool = ..., weights=..., lora_rank: int | None = ..., *, input_length: int | None = ..., activity_regularizer: _Regularizer = ..., trainable: bool = ..., dtype: _LayerDtype | None = ..., autocast: bool = ..., name: str | None = ...) -> None:
        ...



class Conv2D(Layer[tf.Tensor, tf.Tensor]):
    def __init__(self, filters: int, kernel_size: int | Iterable[int], strides: int | Iterable[int] = ..., padding: Literal["valid", "same"] = ..., data_format: None | Literal["channels_last", "channels_first"] = ..., dilation_rate: int | Iterable[int] = ..., groups: int = ..., activation: _Activation = ..., use_bias: bool = ..., kernel_initializer: _Initializer = ..., bias_initializer: _Initializer = ..., kernel_regularizer: _Regularizer = ..., bias_regularizer: _Regularizer = ..., activity_regularizer: _Regularizer = ..., kernel_constraint: _Constraint = ..., bias_constraint: _Constraint = ..., *, trainable: bool = ..., dtype: _LayerDtype | None = ..., autocast: bool = ..., name: str | None = ...) -> None:
        ...



Convolution2D = Conv2D
class Identity(Layer[tf.Tensor, tf.Tensor]):
    def __init__(self, *, activity_regularizer: _Regularizer = ..., trainable: bool = ..., dtype: _LayerDtype | None = ..., autocast: bool = ..., name: str | None = ...) -> None:
        ...



class LayerNormalization(Layer[tf.Tensor, tf.Tensor]):
    def __init__(self, axis: int = ..., epsilon: float = ..., center: bool = ..., scale: bool = ..., rms_scaling: bool = ..., beta_initializer: _Initializer = ..., gamma_initializer: _Initializer = ..., beta_regularizer: _Regularizer = ..., gamma_regularizer: _Regularizer = ..., beta_constraint: _Constraint = ..., gamma_constraint: _Constraint = ..., *, activity_regularizer: _Regularizer = ..., trainable: bool = ..., dtype: _LayerDtype | None = ..., autocast: bool = ..., name: str | None = ...) -> None:
        ...



class MultiHeadAttention(Layer[Any, tf.Tensor]):
    def __init__(self, num_heads: int, key_dim: int | None, value_dim: int | None = ..., dropout: float = ..., use_bias: bool = ..., output_shape: tuple[int, ...] | None = ..., attention_axes: tuple[int, ...] | None = ..., kernel_initializer: _Initializer = ..., bias_initializer: _Initializer = ..., kernel_regularizer: Regularizer | None = ..., bias_regularizer: _Regularizer | None = ..., activity_regularizer: _Regularizer | None = ..., kernel_constraint: _Constraint | None = ..., bias_constraint: _Constraint | None = ..., seed: int | None = ..., *, trainable: bool = ..., dtype: _LayerDtype | None = ..., autocast: bool = ..., name: str | None = ...) -> None:
        ...

    @overload
    def __call__(self, query: tf.Tensor, value: tf.Tensor, key: tf.Tensor | None, attention_mask: tf.Tensor | None, return_attention_scores: Literal[False], training: bool, use_causal_mask: bool) -> tf.Tensor:
        ...

    @overload
    def __call__(self, query: tf.Tensor, value: tf.Tensor, key: tf.Tensor | None, attention_mask: tf.Tensor | None, return_attention_scores: Literal[True], training: bool, use_causal_mask: bool) -> tuple[tf.Tensor, tf.Tensor]:
        ...

    @overload
    def __call__(self, query: tf.Tensor, value: tf.Tensor, key: tf.Tensor | None = ..., attention_mask: tf.Tensor | None = ..., return_attention_scores: bool = ..., training: bool = ..., use_causal_mask: bool = ...) -> tuple[tf.Tensor, tf.Tensor] | tf.Tensor:
        ...



class GaussianDropout(Layer[tf.Tensor, tf.Tensor]):
    def __init__(self, rate: float, seed: int | None = ..., *, activity_regularizer: _Regularizer = ..., trainable: bool = ..., dtype: _LayerDtype | None = ..., autocast: bool = ..., name: str | None = ...) -> None:
        ...



def __getattr__(name: str):
    ...

class LSTM(Layer):
  def __init__(self,
        units: int,
        activation: str | None='tanh',
        recurrent_activation: str | None='hard_sigmoid',
        use_bias: bool=True,
        kernel_initializer: str='glorot_uniform',
        recurrent_initializer: str='orthogonal',
        bias_initializer: str='zeros',
        unit_forget_bias: bool=True,
        kernel_regularizer: ...=None,
        recurrent_regularizer: ...=None,
        bias_regularizer: ...=None,
        activity_regularizer: ...=None,
        kernel_constraint: ...=None,
        recurrent_constraint: ...=None,
        bias_constraint: ...=None,
        dropout: float=0.,
        recurrent_dropout: float=0.,
        return_sequences: bool=False,
        return_state: bool=False,
        go_backwards: bool=False,
        stateful: bool=False,
        unroll: bool=False,
        **kwargs: Any,
    ):
