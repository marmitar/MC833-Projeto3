"""
This type stub file was generated by pyright.
"""

from os import PathLike
import numpy as np
import numpy.typing as npt
import tensorflow as tf
from _typeshed import Incomplete
from collections.abc import Callable, Container, Iterator
from pathlib import Path
from typing import Any, Literal
from typing_extensions import Self, TypeAlias, deprecated
from tensorflow import Variable
from tensorflow._aliases import ContainerGeneric, ShapeLike, TensorCompatible
from tensorflow.keras.layers import Layer, _InputT_contra, _OutputT_co
from tensorflow.keras.optimizers import Optimizer

_Loss: TypeAlias = str | tf.keras.losses.Loss | Callable[[TensorCompatible, TensorCompatible], tf.Tensor]
_Metric: TypeAlias = str | tf.keras.metrics.Metric | Callable[[TensorCompatible, TensorCompatible], tf.Tensor] | None
class Model(Layer[_InputT_contra, _OutputT_co]):
    _train_counter: tf.Variable
    _test_counter: tf.Variable
    optimizer: Optimizer | None
    @deprecated("Instead, use `model.compute_loss(x, y, y_pred, sample_weight)`.")
    def loss(self, y: TensorCompatible | None, y_pred: TensorCompatible | None, sample_weight=...) -> tf.Tensor | None:
        ...

    stop_training: bool
    def __new__(cls, *args: Any, **kwargs: Any) -> Model[_InputT_contra, _OutputT_co]:
        ...

    def __init__(self, *args: Any, **kwargs: Any) -> None:
        ...

    def __setattr__(self, name: str, value: Any) -> None:
        ...

    def __reduce__(self):
        ...

    def build(self, input_shape: ShapeLike) -> None:
        ...

    def __call__(self, inputs: _InputT_contra, *, training: bool = ..., mask: TensorCompatible | None = ...) -> _OutputT_co:
        ...

    def call(self, inputs: _InputT_contra, training: bool | None = ..., mask: TensorCompatible | None = ...) -> _OutputT_co:
        ...

    def compile(self, optimizer: Optimizer | str = ..., loss: ContainerGeneric[_Loss] | None = ..., loss_weights: ContainerGeneric[float] | None = ..., metrics: ContainerGeneric[_Metric] | None = ..., weighted_metrics: ContainerGeneric[_Metric] | None = ..., run_eagerly: bool = ..., steps_per_execution: int | Literal["auto"] = ..., jit_compile: bool | Literal["auto"] = ..., auto_scale_loss: bool | None = ...) -> None:
        ...

    @property
    def metrics(self) -> list[Incomplete]:
        ...

    @property
    def metrics_names(self) -> list[str]:
        ...

    @property
    def distribute_strategy(self) -> tf.distribute.Strategy:
        ...

    @property
    def run_eagerly(self) -> bool:
        ...

    @property
    def jit_compile(self) -> bool:
        ...

    @property
    def distribute_reduction_method(self) -> Incomplete | Literal["auto"]:
        ...

    def train_step(self, data: TensorCompatible):
        ...

    def compute_loss(self, x: TensorCompatible | None = ..., y: TensorCompatible | None = ..., y_pred: TensorCompatible | None = ..., sample_weight=..., training: bool = ...) -> tf.Tensor | None:
        ...

    def compute_metrics(self, x: TensorCompatible, y: TensorCompatible, y_pred: TensorCompatible, sample_weight=...) -> dict[str, float]:
        ...

    def get_metrics_result(self) -> dict[str, float]:
        ...

    def make_train_function(self, force: bool = ...) -> Callable[[tf.data.Iterator[Incomplete]], dict[str, float]]:
        ...

    def fit(self, x: TensorCompatible | dict[str, TensorCompatible] | tf.data.Dataset[Incomplete] | None = ..., y: TensorCompatible | dict[str, TensorCompatible] | tf.data.Dataset[Incomplete] | None = ..., batch_size: int | None = ..., epochs: int = ..., verbose: Literal["auto", 0, 1, 2] = ..., callbacks: list[tf.keras.callbacks.Callback] | None = ..., validation_split: float = ..., validation_data: TensorCompatible | tf.data.Dataset[Any] | None = ..., shuffle: bool = ..., class_weight: dict[int, float] | None = ..., sample_weight: npt.NDArray[np.float64] | None = ..., initial_epoch: int = ..., steps_per_epoch: int | None = ..., validation_steps: int | None = ..., validation_batch_size: int | None = ..., validation_freq: int | Container[int] = ...) -> tf.keras.callbacks.History:
        ...

    def test_step(self, data: TensorCompatible) -> dict[str, float]:
        ...

    def make_test_function(self, force: bool = ...) -> Callable[[tf.data.Iterator[Incomplete]], dict[str, float]]:
        ...

    def evaluate(self, x: TensorCompatible | dict[str, TensorCompatible] | tf.data.Dataset[Incomplete] | None = ..., y: TensorCompatible | dict[str, TensorCompatible] | tf.data.Dataset[Incomplete] | None = ..., batch_size: int | None = ..., verbose: Literal["auto", 0, 1, 2] = ..., sample_weight: npt.NDArray[np.float64] | None = ..., steps: int | None = ..., callbacks: list[tf.keras.callbacks.Callback] | None = ..., return_dict: bool = ..., **kwargs: Any) -> float | list[float]:
        ...

    def predict_step(self, data: _InputT_contra) -> _OutputT_co:
        ...

    def make_predict_function(self, force: bool = ...) -> Callable[[tf.data.Iterator[Incomplete]], _OutputT_co]:
        ...

    def predict(self, x: TensorCompatible | tf.data.Dataset[Incomplete], batch_size: int | None = ..., verbose: Literal["auto", 0, 1, 2] = ..., steps: int | None = ..., callbacks: list[tf.keras.callbacks.Callback] | None = ...) -> _OutputT_co:
        ...

    def reset_metrics(self) -> None:
        ...

    def train_on_batch(self, x: TensorCompatible | dict[str, TensorCompatible] | tf.data.Dataset[Incomplete], y: TensorCompatible | dict[str, TensorCompatible] | tf.data.Dataset[Incomplete] | None = ..., sample_weight: npt.NDArray[np.float64] | None = ..., class_weight: dict[int, float] | None = ..., return_dict: bool = ...) -> float | list[float]:
        ...

    def test_on_batch(self, x: TensorCompatible | dict[str, TensorCompatible] | tf.data.Dataset[Incomplete], y: TensorCompatible | dict[str, TensorCompatible] | tf.data.Dataset[Incomplete] | None = ..., sample_weight: npt.NDArray[np.float64] | None = ..., return_dict: bool = ...) -> float | list[float]:
        ...

    def predict_on_batch(self, x: Iterator[_InputT_contra]) -> npt.NDArray[Incomplete]:
        ...

    @property
    def trainable_weights(self) -> list[Variable]:
        ...

    @property
    def non_trainable_weights(self) -> list[Variable]:
        ...

    def get_weights(self):
        ...

    def save(self, filepath: str | Path, overwrite: bool = ..., zipped: bool | None = ...) -> None:
        ...

    def save_weights(self, filepath: str | Path, overwrite: bool = ...) -> None:
        ...

    def load_weights(self, filepath: str | Path, skip_mismatch: bool = ..., *, by_name: bool = ...) -> None:
        ...

    def get_config(self) -> dict[str, Any]:
        ...

    @classmethod
    def from_config(cls, config: dict[str, Any], custom_objects=...) -> Self:
        ...

    def to_json(self, **kwargs: Any) -> str:
        ...

    @property
    def weights(self) -> list[Variable]:
        ...

    def summary(self, line_length: None | int = ..., positions: None | list[float] = ..., print_fn: None | Callable[[str], None] = ..., expand_nested: bool = ..., show_trainable: bool = ..., layer_range: None | list[str] | tuple[str, str] = ...) -> None:
        ...

    @property
    def layers(self) -> list[Layer[Incomplete, Incomplete]]:
        ...

    def get_layer(self, name: str | None = ..., index: int | None = ...) -> Layer[Incomplete, Incomplete]:
        ...

    def get_compile_config(self) -> dict[str, Any]:
        ...

    def compile_from_config(self, config: dict[str, Any]) -> Self:
        ...

    def export(self, filepath: str | Path, format: str = ..., verbose: bool = ...) -> None:
        ...

class Sequential(Model):
    ...

def __getattr__(name: str):
    ...


def save_model(
    model: Model,
    filepath: str | PathLike[str],
    overwrite: bool=True,
    include_optimizer: bool=True,
    save_format: bool=None,
    signatures: ...=None,
    options: ...=None,
    save_traces: bool=True
) -> None:
    ...

def load_model(
    filepath: str | PathLike[str],
    custom_objects: dict[str, Any] | None=None,
    compile: bool=True,
    options: ...=None
) -> Model:
    ...
